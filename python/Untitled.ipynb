{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longvb/anaconda3/envs/deepsrl-py3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import json\n",
    "from argparse import Namespace\n",
    "from neural_srl.shared.measurements import Timer\n",
    "from neural_srl.shared.tagger_data import TaggerData\n",
    "from neural_srl.shared import reader\n",
    "import os\n",
    "import shutil\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Argv = namedtuple(\"Argv\", \"config dev gold labels model task train vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Argv(config='../config/srl_small_config.json', dev='../data/srl/conll2012.devel.txt', gold='../data/srl/conll2012.devel.props.gold.txt', labels='', model='conll2012_small_model', task='srl', train='../data/srl/conll2012.train.txt', vocab='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../config/srl_small_config.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(config_filepath):\n",
    "  with open(config_filepath, 'r') as config_file: \n",
    "    conf = json.load(config_file, object_hook=lambda d: Namespace(**d))\n",
    "  return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(args.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "global_step = 0\n",
    "epoch = 0\n",
    "train_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: srl\n",
      "(['In', 'recent', 'years', ',', 'advanced', 'education', 'for', 'professionals', 'has', 'become', 'a', 'hot', 'topic', 'in', 'the', 'business', 'community', '.'], 5, ['O', 'O', 'O', 'O', 'B-ARGM-ADJ', 'B-V', 'B-ARG1', 'I-ARG1', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])\n",
      "(['President', 'Chen', 'Travels', 'Abroad'], 2, ['B-ARG0', 'I-ARG0', 'B-V', 'B-ARGM-ADV'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features\n",
      "Extraced 43852 words and 129 tags\n",
      "Max training sentence length: 210\n",
      "Max development sentence length: 275\n",
      "Dev data has 71 batches.\n",
      "Data loading duration was 0:00:21.\n"
     ]
    }
   ],
   "source": [
    "with Timer('Data loading'):\n",
    "    vocab_path = args.vocab if args.vocab != '' else None\n",
    "    label_path = args.labels if args.labels != '' else None\n",
    "    gold_props_path = args.gold if args.gold != '' else None\n",
    "    \n",
    "    print ('Task: {}'.format(args.task))\n",
    "    \n",
    "    data = TaggerData(config,\n",
    "                        *reader.get_srl_data(config, args.train, args.dev, vocab_path, label_path))\n",
    "    \n",
    "    batched_dev_data = data.get_development_data(batch_size=config.dev_batch_size)\n",
    "    print ('Dev data has {} batches.'.format(len(batched_dev_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1, 14, 15, 16, 17]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_sents[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in recent years , advanced education for professionals has become a hot topic in the business community .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([data.word_dict.idx2str[i] for i in data.train_sents[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_sents[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_sents[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O O O O B-ARGM-ADJ B-V B-ARG1 I-ARG1 O O O O O O O O O O'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([data.label_dict.idx2str[i] for i in data.train_sents[0][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-ARGM-ADJ', 'B-V']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label_dict.idx2str[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Log directory conll2012_small_model is not empty, previous checkpoints might be overwritten\n",
      "Preparation duration was 0:00:00.\n"
     ]
    }
   ],
   "source": [
    "with Timer('Preparation'):\n",
    "    if not os.path.isdir(args.model):\n",
    "      print ('Directory {} does not exist. Creating new.'.format(args.model))\n",
    "      os.makedirs(args.model)\n",
    "    else:\n",
    "      if len(os.listdir(args.model)) > 0:\n",
    "        print ('[WARNING] Log directory {} is not empty, previous checkpoints might be overwritten'\n",
    "             .format(args.model))\n",
    "    shutil.copyfile(args.config, os.path.join(args.model, 'config'))\n",
    "    # Save word and label dict to model directory.\n",
    "    data.word_dict.save(os.path.join(args.model, 'word_dict'))\n",
    "    data.label_dict.save(os.path.join(args.model, 'label_dict'))\n",
    "    writer = open(os.path.join(args.model, 'checkpoints.tsv'), 'w')\n",
    "    writer.write('step\\tdatetime\\tdev_loss\\tdev_accuracy\\tbest_dev_accuracy\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conll2012_small_model'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 252315 samples and 3154 batches.\n"
     ]
    }
   ],
   "source": [
    "train_data = data.get_training_data(include_last_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cc\n",
      "Building model duration was 0:00:00.\n"
     ]
    }
   ],
   "source": [
    "with Timer('Building model'):\n",
    "#     model = BiLSTMTaggerModel(data, config=config)  \n",
    "#     for param in model.params:\n",
    "#       print(param, param.name, param.shape.eval())\n",
    "#     loss_function = model.get_loss_function()\n",
    "#     eval_function = model.get_eval_function()\n",
    "    print(\"cc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070 Ti'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
