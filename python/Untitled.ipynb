{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longvb/anaconda3/envs/deepsrl-py3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "import json\n",
    "from argparse import Namespace\n",
    "from neural_srl.shared.measurements import Timer\n",
    "from neural_srl.shared.tagger_data import TaggerData\n",
    "from neural_srl.shared import reader\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from neural_srl.theano.tagger import BiLSTMTaggerModel\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Argv = namedtuple(\"Argv\", \"config dev gold labels model task train vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Argv(config='../config/srl_small_config.json', dev='../data/srl/conll2012.devel.txt', gold='../data/srl/conll2012.devel.props.gold.txt', labels='', model='conll2012_small_model', task='srl', train='../data/srl/conll2012.train.txt', vocab='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../config/srl_small_config.json'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(config_filepath):\n",
    "  with open(config_filepath, 'r') as config_file: \n",
    "    conf = json.load(config_file, object_hook=lambda d: Namespace(**d))\n",
    "  return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config(args.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "global_step = 0\n",
    "epoch = 0\n",
    "train_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: srl\n",
      "(['In', 'recent', 'years', ',', 'advanced', 'education', 'for', 'professionals', 'has', 'become', 'a', 'hot', 'topic', 'in', 'the', 'business', 'community', '.'], 5, ['O', 'O', 'O', 'O', 'B-ARGM-ADJ', 'B-V', 'B-ARG1', 'I-ARG1', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'])\n",
      "(['President', 'Chen', 'Travels', 'Abroad'], 2, ['B-ARG0', 'I-ARG0', 'B-V', 'B-ARGM-ADV'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features\n",
      "Extraced 43852 words and 129 tags\n",
      "Max training sentence length: 210\n",
      "Max development sentence length: 275\n",
      "Dev data has 552 batches.\n",
      "Data loading duration was 0:00:21.\n"
     ]
    }
   ],
   "source": [
    "with Timer('Data loading'):\n",
    "    vocab_path = args.vocab if args.vocab != '' else None\n",
    "    label_path = args.labels if args.labels != '' else None\n",
    "    gold_props_path = args.gold if args.gold != '' else None\n",
    "    \n",
    "    print ('Task: {}'.format(args.task))\n",
    "    \n",
    "    data = TaggerData(config,\n",
    "                        *reader.get_srl_data(config, args.train, args.dev, vocab_path, label_path))\n",
    "    \n",
    "    batched_dev_data = data.get_development_data(batch_size=config.dev_batch_size)\n",
    "    print ('Dev data has {} batches.'.format(len(batched_dev_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 1, 14, 15, 16, 17]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_sents[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in recent years , advanced education for professionals has become a hot topic in the business community .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([data.word_dict.idx2str[i] for i in data.train_sents[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_sents[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_sents[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O O O O O O O O O O O O O O O O O O O O O O O B-ARG0 O O O B-V B-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 O'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([data.label_dict.idx2str[i] for i in data.train_sents[12][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-ARGM-ADJ', 'B-V']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label_dict.idx2str[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252315"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.train_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  0],\n",
       "        [ 2,  0],\n",
       "        [ 3,  0],\n",
       "        [ 4,  0],\n",
       "        [ 5,  0],\n",
       "        [ 6,  1],\n",
       "        [ 7,  0],\n",
       "        [ 8,  0],\n",
       "        [ 9,  0],\n",
       "        [10,  0],\n",
       "        [11,  0],\n",
       "        [12,  0],\n",
       "        [13,  0],\n",
       "        [ 1,  0],\n",
       "        [14,  0],\n",
       "        [15,  0],\n",
       "        [16,  0],\n",
       "        [17,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0]]),\n",
       " array([0, 0, 0, 0, 1, 2, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 18,\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] Log directory conll2012_small_model is not empty, previous checkpoints might be overwritten\n",
      "Preparation duration was 0:00:00.\n"
     ]
    }
   ],
   "source": [
    "with Timer('Preparation'):\n",
    "    if not os.path.isdir(args.model):\n",
    "      print ('Directory {} does not exist. Creating new.'.format(args.model))\n",
    "      os.makedirs(args.model)\n",
    "    else:\n",
    "      if len(os.listdir(args.model)) > 0:\n",
    "        print ('[WARNING] Log directory {} is not empty, previous checkpoints might be overwritten'\n",
    "             .format(args.model))\n",
    "    shutil.copyfile(args.config, os.path.join(args.model, 'config'))\n",
    "    # Save word and label dict to model directory.\n",
    "    data.word_dict.save(os.path.join(args.model, 'word_dict'))\n",
    "    data.label_dict.save(os.path.join(args.model, 'label_dict'))\n",
    "    writer = open(os.path.join(args.model, 'checkpoints.tsv'), 'w')\n",
    "    writer.write('step\\tdatetime\\tdev_loss\\tdev_accuracy\\tbest_dev_accuracy\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conll2012_small_model'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 252315 samples and 1972 batches.\n"
     ]
    }
   ],
   "source": [
    "train_data = data.get_training_data(include_last_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train_data[0][3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(train_data[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-ARGM-DIS B-ARGM-TMP O O B-V B-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 I-ARG1 O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([data.label_dict.idx2str[i] for i in train_data[312][1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 feature types, projected output dim=200.\n",
      "lstm_0_rdrop 0.1 True\n",
      "<neural_srl.theano.layer.HighwayLSTMLayer object at 0x7f3a1316fa60>\n",
      "lstm_1_rdrop 0.1 True\n",
      "<neural_srl.theano.layer.HighwayLSTMLayer object at 0x7f3a1316e9e0>\n",
      "embedding_0 embedding_0 [43852   100]\n",
      "embedding_1 embedding_1 [  2 100]\n",
      "lstm_0_W lstm_0_W [ 200 1800]\n",
      "lstm_0_U lstm_0_U [ 300 1500]\n",
      "lstm_0_b lstm_0_b [1800]\n",
      "lstm_1_W lstm_1_W [ 300 1800]\n",
      "lstm_1_U lstm_1_U [ 300 1500]\n",
      "lstm_1_b lstm_1_b [1800]\n",
      "softmax_W softmax_W [300 129]\n",
      "softmax_b softmax_b [129]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longvb/anaconda3/envs/deepsrl-py3/lib/python3.10/site-packages/theano/scan_module/scan_perform_ext.py:75: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  warnings.warn(\n",
      "/home/longvb/anaconda3/envs/deepsrl-py3/lib/python3.10/site-packages/theano/scan_module/scan_perform_ext.py:75: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  warnings.warn(\n",
      "/home/longvb/anaconda3/envs/deepsrl-py3/lib/python3.10/site-packages/theano/scan_module/scan_perform_ext.py:75: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  warnings.warn(\n",
      "/home/longvb/anaconda3/envs/deepsrl-py3/lib/python3.10/site-packages/theano/scan_module/scan_perform_ext.py:75: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model duration was 0:00:12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longvb/anaconda3/envs/deepsrl-py3/lib/python3.10/site-packages/theano/scan_module/scan_perform_ext.py:75: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  warnings.warn(\n",
      "/home/longvb/anaconda3/envs/deepsrl-py3/lib/python3.10/site-packages/theano/scan_module/scan_perform_ext.py:75: UserWarning: The file scan_perform.c is not available. This donot happen normally. You are probably in a strangesetup. This mean Theano can not use the cython code for scan. If youwant to remove this warning, use the Theano flag'cxx=' (set to an empty string) to disable all ccode generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with Timer('Building model'):\n",
    "    model = BiLSTMTaggerModel(data, config=config)  \n",
    "    for param in model.params:\n",
    "      print(param, param.name, param.shape.eval())\n",
    "    loss_function = model.get_loss_function()\n",
    "    eval_function = model.get_eval_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n"
     ]
    }
   ],
   "source": [
    "for batched_tensor in train_data:\n",
    "    print(\"Start\")\n",
    "    x, y, _, weights = batched_tensor\n",
    "    loss, *inputs = loss_function(x, weights, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 128, 200)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(120.36957783)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070 Ti'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[43852, 100], [2, 100]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.embedding_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(43852, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Embedding.from_pretrained(torch.tensor(data.embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43852"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.word_dict.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43852"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label_dict.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BIOModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_layers, hidden_dim, pretrained_embedding):\n",
    "        super(BIOModel, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embed = nn.Embedding.from_pretrained(pretrained_embedding)\n",
    "        self.mask_embed = nn.Embedding(2, embedding_dim, device=device)\n",
    "        \n",
    "        self.biLSTM = nn.LSTM(embedding_dim * 2, hidden_dim, n_layers, dropout=0.1, bidirectional=True, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim * 2, data.label_dict.size())\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, sequence_length = x.size(0), x.size(1)\n",
    "        x_w = self.word_embed(x[:,:,0])\n",
    "        x_m = self.mask_embed(x[:,:,1])\n",
    "        x = torch.concat((x_w, x_m), axis=2)\n",
    "        \n",
    "        hidden_state, cell_state = self.init_hidden(batch_size)\n",
    "        \n",
    "        output, (hidden_state, cell_state) = self.biLSTM(x, (hidden_state, cell_state))\n",
    "        \n",
    "        output = self.linear(output)\n",
    "        scores = self.softmax(output)\n",
    "        pred = torch.argmax(scores, dim=-1)\n",
    "        \n",
    "        return output, pred\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros((self.n_layers * 2, batch_size, self.hidden_dim), device=device)\n",
    "        c0 = torch.zeros((self.n_layers * 2, batch_size, self.hidden_dim), device=device)\n",
    "        return h0, c0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding = torch.tensor(data.embeddings[0], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bioModel = BIOModel(data.word_dict.size(), \n",
    "                    embedding_dim=len(data.embeddings[0][0]), \n",
    "                    n_layers=4, hidden_dim=model.lstm_hidden_size, \n",
    "                    pretrained_embedding=pretrained_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BIOModel(\n",
       "  (word_embed): Embedding(43852, 100)\n",
       "  (mask_embed): Embedding(2, 100)\n",
       "  (biLSTM): LSTM(200, 300, num_layers=4, batch_first=True, dropout=0.1, bidirectional=True)\n",
       "  (linear): Linear(in_features=600, out_features=129, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bioModel.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 100, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = torch.stack([torch.tensor(i, device=device) for i in x])\n",
    "x_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, preds = bioModel(x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(scores, y):\n",
    "    # targets = torch.reshape(y, [y.shape[0] * y.shape[1]])\n",
    "    # scores_flatten = torch.reshape(scores, (scores.shape[0] * scores.shape[1], -1))\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    return ce_loss(scores.permute((0,2,1)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor = torch.stack([torch.tensor(i, device=device) for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8391, device='cuda:0', grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(scores, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adadelta, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = Adadelta(bioModel.parameters(), rho=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(bioModel.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model):\n",
    "    flatten_ys = []\n",
    "    flatten_preds = []\n",
    "    for i, batch in enumerate(tqdm(batched_dev_data)):\n",
    "        x, y, sq_lengths, weights = batch\n",
    "        x_tensor = torch.stack([torch.tensor(i, device=device) for i in x])\n",
    "        y_tensor = torch.stack([torch.tensor(i, device=device) for i in y])\n",
    "\n",
    "        scores, preds = bioModel(x_tensor)\n",
    "        \n",
    "        for i, y in enumerate(y_tensor):\n",
    "            \n",
    "            flatten_y_list = y_tensor[i][:sq_lengths[i]].cpu().tolist()\n",
    "            flatten_pred = preds[i][:sq_lengths[i]].cpu().tolist()\n",
    "            flatten_ys = flatten_ys + flatten_y_list\n",
    "            flatten_preds = flatten_preds + flatten_pred\n",
    "\n",
    "    f1 = sklearn.metrics.f1_score(flatten_ys, flatten_preds, average=\"macro\")\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation(bioModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn):\n",
    "    train_data = data.get_training_data(include_last_batch=True)\n",
    "    best_f1 = 0\n",
    "    for epoch in range(config.max_epochs):\n",
    "        print(f\"Epoch: {epoch + 1}\")\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for i, batch in enumerate(tqdm(train_data)):\n",
    "            x, y, _, weights = batched_tensor\n",
    "            x_tensor = torch.stack([torch.tensor(i, device=device) for i in x])\n",
    "            y_tensor = torch.stack([torch.tensor(i, device=device) for i in y])\n",
    "            \n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            scores, preds = model(x_tensor)\n",
    "            \n",
    "            # print(scores.shape)\n",
    "            # print(y_tensor.shape)\n",
    "            # return\n",
    "            \n",
    "            loss = loss_fn(scores, y_tensor)\n",
    "            train_loss += loss\n",
    "            \n",
    "            loss.backward()\n",
    "            # torch.nn.utils.clip_grad_norm(model.parameters(), float(config.max_grad_norm))\n",
    "            optimizer.step()\n",
    "            \n",
    "        i += 1\n",
    "        train_loss = train_loss / i\n",
    "        print(\"Epoch {}, steps={}, loss={:.6f}\".format(epoch + 1, i, train_loss))\n",
    "        model.eval()\n",
    "        f1_dev = evaluation(model)\n",
    "        if f1_dev > best_f1:\n",
    "            torch.save(model.state_dict(), os.path.join(args.model, f\"out-epoch-{epoch}-{datetime.now().strftime('%d-%m-%Y_%H')}.pt\"))\n",
    "        print(\"Eval: macro f1={:.3f}, best f1={:.3f}\".format(f1_dev, best_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss ma van con giu nguyen la t dap may chet me may\n"
     ]
    }
   ],
   "source": [
    "print(\"Loss ma van con giu nguyen la t dap may chet me may\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 252315 samples and 1972 batches.\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:57<00:00, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, steps=1972, loss=0.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:17<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.050\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:56<00:00, 16.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, steps=1972, loss=0.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:31<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.054\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:57<00:00, 16.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, steps=1972, loss=0.010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:15<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.057\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:54<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, steps=1972, loss=0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:30<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.059\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:55<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, steps=1972, loss=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:29<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.059\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:53<00:00, 17.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, steps=1972, loss=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:15<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.060\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:50<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, steps=1972, loss=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:14<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.060\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:50<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, steps=1972, loss=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:14<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.061\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:55<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, steps=1972, loss=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:15<00:00,  7.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.061\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:56<00:00, 16.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, steps=1972, loss=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:16<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.061\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:54<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, steps=1972, loss=0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:14<00:00,  7.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.062\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 1972/1972 [01:55<00:00, 17.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, steps=1972, loss=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 552/552 [01:15<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: macro f1=0.063\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████████▉                                                   | 422/1972 [00:25<01:37, 15.93it/s]"
     ]
    }
   ],
   "source": [
    "train(bioModel, optimizer, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
